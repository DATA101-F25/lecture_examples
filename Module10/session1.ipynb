{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "984a5cf5",
   "metadata": {},
   "source": [
    "\n",
    "# DATA 101 — Module 10, Session 1 Demo  \n",
    "**Classification basics: Logistic Regression and Decision Trees**\n",
    "\n",
    "This notebook mirrors the lecture:\n",
    "- Binary classification setup\n",
    "- Train/test split\n",
    "- Logistic regression and decision tree\n",
    "- Confusion matrix, precision, recall, F1, accuracy\n",
    "- ROC curve and AUC\n",
    "- Threshold effects\n",
    "- Brief model comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076ada24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_curve,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "# Data\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_STATE = 1\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a7dff6",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Data\n",
    "Use the Breast Cancer Wisconsin dataset. Target: malignant (1) vs benign (0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28291fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target, name=\"target\")  # 0 = malignant? In this dataset: 0 = malignant, 1 = benign\n",
    "# To match lecture convention \"class 1 = positive\", set positive class = malignant.\n",
    "# Flip target so that 1 = malignant, 0 = benign.\n",
    "y = 1 - y\n",
    "\n",
    "X.shape, y.value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba79f6f",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Train/Test Split\n",
    "70% train, 30% test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6c8287",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed769b9",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Logistic Regression\n",
    "Fit, predict, and evaluate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4256da7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(max_iter=5000, solver=\"lbfgs\")\n",
    "logit.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = logit.predict(X_test)\n",
    "y_proba_lr = logit.predict_proba(X_test)[:, 1]\n",
    "\n",
    "acc_lr  = accuracy_score(y_test, y_pred_lr)\n",
    "prec_lr = precision_score(y_test, y_pred_lr, zero_division=0)\n",
    "rec_lr  = recall_score(y_test, y_pred_lr, zero_division=0)\n",
    "f1_lr   = f1_score(y_test, y_pred_lr, zero_division=0)\n",
    "auc_lr  = roc_auc_score(y_test, y_proba_lr)\n",
    "\n",
    "report_lr = classification_report(y_test, y_pred_lr, target_names=[\"benign(0)\",\"malignant(1)\"])\n",
    "\n",
    "cm_lr = pd.DataFrame(confusion_matrix(y_test, y_pred_lr),\n",
    "                     index=[\"Actual 0\",\"Actual 1\"],\n",
    "                     columns=[\"Pred 0\",\"Pred 1\"])\n",
    "\n",
    "print(\"Logistic Regression — test metrics\")\n",
    "print(pd.Series({\n",
    "    \"accuracy\": acc_lr,\n",
    "    \"precision\": prec_lr,\n",
    "    \"recall\": rec_lr,\n",
    "    \"f1\": f1_lr,\n",
    "    \"auc\": auc_lr\n",
    "}).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c80cc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nConfusion matrix:\")\n",
    "display(cm_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96f7b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification report:\")\n",
    "print(report_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b334f1",
   "metadata": {},
   "source": [
    "\n",
    "### ROC Curve and AUC — Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5553bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_proba_lr)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr_lr, tpr_lr, label=f\"Logistic (AUC={auc_lr:.3f})\")\n",
    "plt.plot([0,1],[0,1], linestyle=\"--\", label=\"Random\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve — Logistic Regression\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2cb194",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Threshold Effects\n",
    "By default, `predict` uses threshold 0.5. Try 0.30 and 0.70 to see precision/recall trade-offs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfc65dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_at_threshold(y_true, y_proba, thr):\n",
    "    y_pred = (y_proba >= thr).astype(int)\n",
    "    return {\n",
    "        \"threshold\": thr,\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"f1\": f1_score(y_true, y_pred, zero_division=0)\n",
    "    }\n",
    "\n",
    "rows = [evaluate_at_threshold(y_test, y_proba_lr, t) for t in [0.30, 0.50, 0.70]]\n",
    "pd.DataFrame(rows).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd37a5f8",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Decision Tree\n",
    "Depth-limited to control overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a38230",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=3, random_state=RANDOM_STATE)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt = tree.predict(X_test)\n",
    "y_proba_dt = tree.predict_proba(X_test)[:, 1]\n",
    "\n",
    "acc_dt  = accuracy_score(y_test, y_pred_dt)\n",
    "prec_dt = precision_score(y_test, y_pred_dt, zero_division=0)\n",
    "rec_dt  = recall_score(y_test, y_pred_dt, zero_division=0)\n",
    "f1_dt   = f1_score(y_test, y_pred_dt, zero_division=0)\n",
    "auc_dt  = roc_auc_score(y_test, y_proba_dt)\n",
    "\n",
    "report_dt = classification_report(y_test, y_pred_dt, target_names=[\"benign(0)\",\"malignant(1)\"])\n",
    "\n",
    "cm_dt = pd.DataFrame(confusion_matrix(y_test, y_pred_dt),\n",
    "                     index=[\"Actual 0\",\"Actual 1\"],\n",
    "                     columns=[\"Pred 0\",\"Pred 1\"])\n",
    "\n",
    "print(\"Decision Tree — test metrics\")\n",
    "print(pd.Series({\n",
    "    \"accuracy\": acc_dt,\n",
    "    \"precision\": prec_dt,\n",
    "    \"recall\": rec_dt,\n",
    "    \"f1\": f1_dt,\n",
    "    \"auc\": auc_dt\n",
    "}).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67647a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nConfusion matrix:\")\n",
    "display(cm_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a235c427",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification report:\")\n",
    "print(report_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d0eaed",
   "metadata": {},
   "source": [
    "\n",
    "### Visualize the Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2718dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "plot_tree(tree, filled=True, feature_names=X.columns, class_names=[\"benign(0)\",\"malignant(1)\"], rounded=True)\n",
    "plt.title(\"Decision Tree (max_depth=3)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da99e847",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Quick Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f59839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame([\n",
    "    {\"model\":\"Logistic Regression\",\"accuracy\":acc_lr,\"precision\":prec_lr,\"recall\":rec_lr,\"f1\":f1_lr,\"auc\":auc_lr},\n",
    "    {\"model\":\"Decision Tree (depth=3)\",\"accuracy\":acc_dt,\"precision\":prec_dt,\"recall\":rec_dt,\"f1\":f1_dt,\"auc\":auc_dt},\n",
    "]).round(4)\n",
    "\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8302103a",
   "metadata": {},
   "source": [
    "### ROC Curves — Both Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb84dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_dt, tpr_dt, _ = roc_curve(y_test, y_proba_dt)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr_lr, tpr_lr, label=f\"Logistic (AUC={auc_lr:.3f})\")\n",
    "plt.plot(fpr_dt, tpr_dt, label=f\"Decision Tree (AUC={auc_dt:.3f})\")\n",
    "plt.plot([0,1],[0,1], linestyle=\"--\", label=\"Random\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curves — Logistic vs Decision Tree\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3988fab0",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Takeaways\n",
    "- Classification predicts labels; probabilities help set thresholds.\n",
    "- Accuracy can mislead with imbalance. Precision and recall reveal trade-offs.\n",
    "- AUC summarizes ranking quality across thresholds.\n",
    "- Logistic regression is a strong baseline and interpretable via coefficients.\n",
    "- Trees are intuitive but can overfit without constraints.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
