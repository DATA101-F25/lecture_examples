{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8da5e2ec",
   "metadata": {},
   "source": [
    "# Data 101 — Module 5 Assignment\n",
    "\n",
    "**What you will practice:**\n",
    "- Importing and using libraries (`numpy`, `pandas`)\n",
    "- Array creation, slicing, broadcasting, reshaping\n",
    "- DataFrame creation, selection with `loc`/`iloc`, boolean filtering\n",
    "- Data wrangling: missing values, types, duplicates, outliers\n",
    "- Summarizing with `groupby`, `agg`, and pivot tables\n",
    "\n",
    "**Rules:**\n",
    "- Write your code in the `#TODO` sections only.\n",
    "- Do not change variable or function names.\n",
    "- You may add new cells for scratch work.\n",
    "\n",
    "**Grading rubric:** 100 points total\n",
    "- A. NumPy (30 pts)\n",
    "- B. Pandas basics (25 pts)\n",
    "- C. Wrangling & summarizing (45 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceb201c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versions: {'numpy': '2.3.3', 'pandas': '2.3.2'}\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Display options for readability\n",
    "pd.set_option(\"display.max_rows\", 20)\n",
    "pd.set_option(\"display.max_columns\", 20)\n",
    "print(\"Versions:\", {\"numpy\": np.__version__, \"pandas\": pd.__version__})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bc7bfb",
   "metadata": {},
   "source": [
    "## Part A — NumPy (30 pts)\n",
    "Work only where marked `#TODO`. Keep the variable names as given."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0555af",
   "metadata": {},
   "source": [
    "### A1. Create arrays (5 pts)\n",
    "Create:\n",
    "- `a`: 1D array with values 1..10\n",
    "- `b`: 2D array of shape (3, 4) filled with ones\n",
    "- `c`: 10 numbers linearly spaced from 0 to 1 inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdb7220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSIGNMENT CELL: Q1\n",
    "a = np.arange(1,11,1)\n",
    "b = np.ones(shape=(3,4))\n",
    "c = np.linspace(0,1,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e2f4e6",
   "metadata": {},
   "source": [
    "### A2. Indexing and slicing (10 pts)\n",
    "Using `a` from A1:\n",
    "- Set `a_first` to the first element\n",
    "- Set `a_mid` to elements at positions 3..6 inclusive (1-based: 4..7) via slicing\n",
    "- Using a new array `d = np.arange(12).reshape(3,4)`, set `d_edge` to the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c851d6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSIGNMENT CELL: Q2\n",
    "a_first = a[0]\n",
    "a_mid = a[3:7]\n",
    "d = np.arange(12).reshape(3,4)\n",
    "d_edge = d[:,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8157852f",
   "metadata": {},
   "source": [
    "### A3. Broadcasting and vectorization (10 pts)\n",
    "\n",
    "Let `x = np.array([2, 4, 6, 8])`.\n",
    "\n",
    "- Use a single vectorized expression to scale each element by 10 (* 10) and then shift the result by 1 (+ 1). Store in `y`.\n",
    "- Use broadcasting to combine `x` with a column vector of shape (2,1), so that the result has shape (2,4). The first row should reproduce `x`, and the second row should be `x` shifted by one unit (+ 1). Store in `z`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb5082e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSIGNMENT CELL: Q3\n",
    "x = np.array([2,4,6,8])\n",
    "y = x * 10 + 1\n",
    "z = x + np.array([[0],[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2c0778",
   "metadata": {},
   "source": [
    "### A4. Reshape and combine (5 pts)\n",
    "- Reshape `a` into a 2D array `a2` with shape (2,5)\n",
    "- Vertically stack `a2` on top of itself to form `a3` with shape (4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5f7d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSIGNMENT CELL: Q4\n",
    "a2 = a.reshape((2,5))\n",
    "a3 = np.vstack([a2,a2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fafdf32",
   "metadata": {},
   "source": [
    "## Part B — Pandas basics (25 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc50e58",
   "metadata": {},
   "source": [
    "### B1. Load and inspect (5 pts)\n",
    "Load the CSV at `./data/students_messy.csv` into `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748b3e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSIGNMENT CELL: Q5\n",
    "df = pd.read_csv(\"./data/students_messy.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599afb71",
   "metadata": {},
   "source": [
    "### B2. Column and row selection (15 pts)\n",
    "- Set `gpa_series` to the `GPA` column as a Series\n",
    "- Set `name_gpa_df` to a DataFrame with columns `Name` and `GPA`\n",
    "- Using `loc`, select rows 1..3 inclusive into `mid_rows`\n",
    "- Using `iloc`, select all rows and the first two columns into `first_two_cols`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacf5d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSIGNMENT CELL: Q6\n",
    "gpa_series = df[\"GPA\"]\n",
    "name_gpa_df = df[[\"Name\", \"GPA\"]]\n",
    "mid_rows = df.loc[1:3]\n",
    "first_two_cols = df.iloc[:,0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9b603d",
   "metadata": {},
   "source": [
    "### B3. Boolean filtering (5 pts)\n",
    "Filter to rows with `GPA >= 3.5` into `high_gpa`. Use numeric comparison, not strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa8ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSIGNMENT CELL: Q7\n",
    "high_gpa = df[df[\"GPA\"] >= 3.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b39810",
   "metadata": {},
   "source": [
    "## Part C — Wrangling & summarizing (45 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7d56e3",
   "metadata": {},
   "source": [
    "### C1. Clean data (20 pts)\n",
    "\n",
    "A new DataFrame named `df_clean` is created from `df`. Do all of the following in this new DataFrame:\n",
    "\n",
    "- Fix text: remove spaces, make `Major` title case\n",
    "- Convert `GPA` and `Hours_Studied` to numbers\n",
    "- Convert `ExamDate` to dates\n",
    "- Remove duplicate rows\n",
    "- Fill missing `GPA` with the mean\n",
    "- Convert `Major` and `Gender` to category\n",
    "\n",
    "After this, `df_clean` should have these types:  \n",
    "`Name` (object), `Major` (category), `GPA` (float), `Hours_Studied` (float), `Gender` (category), `ExamDate` (datetime)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f9f228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSIGNMENT CELL: Q8\n",
    "df_clean = df.copy()\n",
    "df_clean[\"Major\"] = df_clean[\"Major\"].str.strip().str.title()\n",
    "df_clean[\"GPA\"] = pd.to_numeric(df_clean[\"GPA\"], errors=\"coerce\")\n",
    "df_clean[\"Hours_Studied\"] = pd.to_numeric(df_clean[\"Hours_Studied\"], errors=\"coerce\")\n",
    "df_clean[\"ExamDate\"] = pd.to_datetime(df_clean[\"ExamDate\"], errors=\"coerce\")\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "df_clean[\"GPA\"] = df_clean[\"GPA\"].fillna(df_clean[\"GPA\"].mean())\n",
    "df_clean[\"Major\"] = df_clean[\"Major\"].astype(\"category\")\n",
    "df_clean[\"Gender\"] = df_clean[\"Gender\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d42fc2",
   "metadata": {},
   "source": [
    "### C2. Outlier handling (5 pts)\n",
    "Use the IQR rule on `GPA` to filter to `df_no_outliers` that keeps rows within `[Q1 - 1.5*IQR, Q3 + 1.5*IQR]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c98291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSIGNMENT CELL: Q9\n",
    "q1, q3 = df[\"GPA\"].quantile([0.25, 0.75])\n",
    "iqr = q3 - q1\n",
    "lower, upper = q1 - 1.5*iqr, q3 + 1.5*iqr\n",
    "df_no_outliers = df[(df[\"GPA\"] >= lower) & (df[\"GPA\"] <= upper)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85ef598",
   "metadata": {},
   "source": [
    "### C3. Derived columns (5 pts)\n",
    "Add a `Failed` column to `df_clean` that is `'Yes'` if `GPA < 2.0` else `'No'`. Add a `Study_Efficiency` column defined as `GPA / Hours_Studied`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9bfcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSIGNMENT CELL: Q10\n",
    "df_clean[\"Failed\"] = np.where(df_clean[\"GPA\"] < 2.0, \"Yes\", \"No\")\n",
    "df_clean[\"Study_Efficiency\"] = df_clean[\"GPA\"] / df_clean[\"Hours_Studied\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9dd0a7",
   "metadata": {},
   "source": [
    "### C4. Grouping and aggregation (10 pts)\n",
    "Group by `Major` and compute:\n",
    "- `GPA_mean` and `GPA_std`\n",
    "- `Hours_mean`\n",
    "Assign the result to `by_major`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0c4a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSIGNMENT CELL: Q11\n",
    "by_major = df_clean.groupby(\"Major\", observed=True).agg(\n",
    "    GPA_mean=(\"GPA\",\"mean\"),\n",
    "    GPA_std=(\"GPA\",\"std\"),\n",
    "    Hours_mean=(\"Hours_Studied\",\"mean\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016371a0",
   "metadata": {},
   "source": [
    "### C5. Pivot table (5 pts)\n",
    "\n",
    "Make a pivot table named `gpa_by_major_gender`.  \n",
    "- Use `Major` as the index (rows).  \n",
    "- Use `Gender` as the columns.  \n",
    "- The values should be the **maximum GPA** within each Major–Gender group.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3588454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSIGNMENT CELL: Q12\n",
    "gpa_by_major_gender = df_clean.pivot_table(values=\"GPA\", index=\"Major\",\n",
    "    columns=\"Gender\", aggfunc=\"max\", observed=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
